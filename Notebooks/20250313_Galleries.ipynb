{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1f252b-45b4-4811-8170-305458f44877",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec086f2-1507-48f3-b5fa-4b75d9595f74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_projection_montage(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure output folder exists\n",
    "    \n",
    "    # Regex to match files containing '-F4' to '-F11' and extract Name1_name2 part\n",
    "    pattern = re.compile(r'(.+)_([^-]+) - (.+)_(\\w+_\\w+)\\.tif')\n",
    "    \n",
    "    grouped_files = {}\n",
    "    \n",
    "    # Group files by Name1_name2\n",
    "    for filename in os.listdir(input_folder):\n",
    "        match = pattern.match(filename)\n",
    "        if filename.endswith(\".tif\") and match:\n",
    "            base_name, time, specific, name_pair = match.groups()\n",
    "            if name_pair not in grouped_files:\n",
    "                grouped_files[name_pair] = []\n",
    "            grouped_files[name_pair].append((time, filename))\n",
    "    \n",
    "    for name_pair, file_list in grouped_files.items():\n",
    "        file_list.sort()  # Sort by time for ordered montage\n",
    "        projections = []\n",
    "\n",
    "        output_path = os.path.join(output_folder, f\"{name_pair}_montage.tif\")\n",
    "        # Skip processing if the montage file already exists\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"Skipping {name_pair}, already processed.\")\n",
    "            continue\n",
    "        \n",
    "        for time, filename in file_list:\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            # Read multi-dimensional TIF file with metadata\n",
    "            with tiff.TiffFile(input_path) as tif_file:\n",
    "                img = tif_file.asarray()\n",
    "                metadata = tif_file.pages[0].tags\n",
    "                resolution_tag = metadata.get('XResolution')  # Get resolution if available\n",
    "                pixel_size = 0.1883734  # Default pixel size in microns\n",
    "                if resolution_tag:\n",
    "                    resolution = resolution_tag.value  # Extract actual value\n",
    "                    pixel_size = resolution[1] / resolution[0]  # Convert to microns per pixel\n",
    "            \n",
    "            if len(img.shape) == 4 and img.shape[1] == 4:  # (Z, C, H, W) format\n",
    "                img = np.moveaxis(img, 1, 0)  # Convert to (C, Z, H, W)\n",
    "                \n",
    "                # Max project channel 3 (index 2) and channel 2 (index 1) only using z 4-16\n",
    "                img = img[:, 5:16, :, :]               \n",
    "                ch3 = np.max(img[2], axis=0)\n",
    "                ch2 = np.max(img[1], axis=0)\n",
    "                \n",
    "                # Find the brightest object in channel 3\n",
    "                min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(ch3)\n",
    "                center_x, center_y = max_loc\n",
    "                \n",
    "                if max_val == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Define cropping bounds (200x200 pixels around the brightest object)\n",
    "                half_size = 100\n",
    "                h, w = ch3.shape\n",
    "                x1, x2 = center_x - half_size, center_x + half_size\n",
    "                y1, y2 = center_y - half_size, center_y + half_size\n",
    "                \n",
    "                pad_x1, pad_x2, pad_y1, pad_y2 = 0, 0, 0, 0\n",
    "                if x1 < 0:\n",
    "                    pad_x1 = abs(x1)\n",
    "                    x1 = 0\n",
    "                if x2 > w:\n",
    "                    pad_x2 = x2 - w\n",
    "                    x2 = w\n",
    "                if y1 < 0:\n",
    "                    pad_y1 = abs(y1)\n",
    "                    y1 = 0\n",
    "                if y2 > h:\n",
    "                    pad_y2 = y2 - h\n",
    "                    y2 = h\n",
    "                \n",
    "                ch3_crop = ch3[y1:y2, x1:x2]\n",
    "                ch2_crop = ch2[y1:y2, x1:x2]\n",
    "                \n",
    "                ch3_padded = cv2.copyMakeBorder(ch3_crop, pad_y1, pad_y2, pad_x1, pad_x2, cv2.BORDER_CONSTANT, value=0)\n",
    "                ch2_padded = cv2.copyMakeBorder(ch2_crop, pad_y1, pad_y2, pad_x1, pad_x2, cv2.BORDER_CONSTANT, value=0)\n",
    "                \n",
    "                # Normalize and merge channels\n",
    "                def safe_normalize(img):\n",
    "                    if np.max(img) == np.min(img):\n",
    "                        return np.zeros_like(img, dtype=np.uint8)\n",
    "                    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "                \n",
    "                ch3_gray = safe_normalize(ch3_padded)\n",
    "                ch2_gray = safe_normalize(ch2_padded)\n",
    "               # merged = cv2.merge((ch3_gray, ch2_gray, np.zeros_like(ch3_gray)))  # Merge as RGB\n",
    "\n",
    "                # Create the merged image with ch3 in cyan and ch2 in grayscale\n",
    "                merged = cv2.merge((ch3_gray, ch3_gray, np.zeros_like(ch3_gray)))  # Cyan channel\n",
    "                grayscale = cv2.merge((ch2_gray, ch2_gray, ch2_gray))  # Grayscale channel\n",
    "                    \n",
    "                # Combine the cyan and grayscale images using max blending to preserve both\n",
    "                final_merged = np.maximum(merged, grayscale)\n",
    "                \n",
    "                projections.append((final_merged, filename, time))\n",
    "        \n",
    "        if projections:\n",
    "            # Sort projections by time and type\n",
    "            im_projections = [p for p in projections if \"_IM_\" in p[1]]\n",
    "            cm_projections = [p for p in projections if \"_CM_\" in p[1]]\n",
    "            \n",
    "            # Arrange in 16-column by 3-row grid\n",
    "            sorted_projections = {\"24h\": [], \"48h\": [], \"72h\": []}\n",
    "            for proj in im_projections + cm_projections:\n",
    "                for key in sorted_projections:\n",
    "                    if key in proj[1]:\n",
    "                        sorted_projections[key].append(proj)\n",
    "                        break\n",
    "            \n",
    "            cols = 16\n",
    "            rows = 3\n",
    "            img_h, img_w, _ = projections[0][0].shape\n",
    "            montage = np.zeros((rows * img_h, cols * img_w, 3), dtype=np.uint8)\n",
    "            \n",
    "            for row_idx, key in enumerate([\"24h\", \"48h\", \"72h\"]):\n",
    "                row_projections = sorted_projections[key]\n",
    "                for idx, (img, filename, _) in enumerate(row_projections):\n",
    "                    if \"_IM_\" in filename:\n",
    "                        col = idx % 8  # Keep within the first 8 columns\n",
    "                    else:\n",
    "                        col = (idx % 8) + 8  # Keep within the last 8 columns\n",
    "                    y1, y2 = row_idx * img_h, (row_idx + 1) * img_h\n",
    "                    x1, x2 = col * img_w, (col + 1) * img_w\n",
    "                    \n",
    "                    montage[y1:y2, x1:x2] = img\n",
    "                  #  filename_short = filename.split(\"ReScan_\")[1]\n",
    "                    \n",
    "                  #  cv2.putText(montage, filename_short, (x1 + 5, y1 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1) # labeling obsolete when the grid order is correct\n",
    "            \n",
    "            \n",
    "            with tiff.TiffWriter(output_path) as tif:\n",
    "                tif.write(montage, metadata={'axes': 'YX', 'XResolution': (1, pixel_size), 'YResolution': (1, pixel_size)})\n",
    "            \n",
    "            print(f'Created montage: {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ff628f-7426-4e1b-9e26-22435cb7bc6a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping CALM1_init, already processed.\n",
      "Skipping CAMSAP1_init, already processed.\n",
      "Skipping KIF11_orig, already processed.\n",
      "Skipping ANAPC11_new, already processed.\n",
      "Skipping APC_new, already processed.\n",
      "Skipping ASPM_init, already processed.\n",
      "Skipping CENPJ_init, already processed.\n",
      "Skipping CENPI_orig, already processed.\n",
      "Skipping CENPF_orig, already processed.\n",
      "Skipping CENPE_orig, already processed.\n",
      "Skipping CENPC_orig, already processed.\n",
      "Skipping AURKA_orig, already processed.\n",
      "Skipping AURKB_orig, already processed.\n",
      "Skipping AURKC_init, already processed.\n",
      "Skipping BIRC5_orig, already processed.\n",
      "Skipping BUB1_orig, already processed.\n",
      "Skipping CDK5RAP2_init, already processed.\n",
      "Skipping CDK1_orig, already processed.\n",
      "Skipping CDCA8_orig, already processed.\n",
      "Skipping CDC42_orig, already processed.\n",
      "Skipping CDC34_init, already processed.\n",
      "Skipping BUB1B_orig, already processed.\n",
      "Skipping BUB3_init, already processed.\n",
      "Skipping CDC20_orig, already processed.\n",
      "Skipping CDC16_orig, already processed.\n",
      "Skipping CCNB1_orig, already processed.\n",
      "Skipping CAMSAP3_init, already processed.\n",
      "Created montage: /Volumes/arxivBeta/_Tobias/Opera/20250204/03_Galleries_V5/CDC27_orig_montage.tif\n",
      "Created montage: /Volumes/arxivBeta/_Tobias/Opera/20250204/03_Galleries_V5/CAMSAP2_init_montage.tif\n",
      "Created montage: /Volumes/arxivBeta/_Tobias/Opera/20250204/03_Galleries_V5/LUC1_init_montage.tif\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"/Volumes/arxivBeta/_Tobias/Opera/20250204/01_Importer\"  \n",
    "output_folder = \"/Volumes/arxivBeta/_Tobias/Opera/20250204/03_Galleries_V5\" \n",
    "\n",
    "max_projection_montage(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
